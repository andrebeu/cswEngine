{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tutorials/layers on how to setup network with softmax layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abeukers/anaconda/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os,re\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from cswEngine import *\n",
    "from cswMturk import *\n",
    "from cswNets import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "simplest case: given st(t) preditct st(t+1)\n",
    "goal: keep thing extendible, but dont get bogged down\n",
    "\n",
    "gen_vect_seq(path_L) [onehot for now], form a vocab (either learned or fixed),\n",
    "\n",
    "FF softmax. gen_data: given path_L,  group pairs of adjacent vectors. train=test. (option: vocab is random vects, vocab is onehot & first layer is linear embedding layer)\n",
    "\n",
    "RNN2 softmax. {x:[st(t),st(t+1)],y:[st(t+2)]}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([\n",
    "            [1,0,0],[1,0,0],\n",
    "            [0,1,0],[0,1,0],\n",
    "            ])\n",
    "Y_train = np.array([\n",
    "            [1,0,0],[1,0,0],\n",
    "            [0,1,0],[0,1,0],\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session().as_default() as sess:\n",
    "  init = tf.global_variables_initializer()\n",
    "  sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.1309894\n",
      "25 1.1304338\n",
      "50 1.1277348\n",
      "75 1.1141677\n",
      "100 1.0922004\n",
      "125 1.0158594\n",
      "150 1.0065382\n",
      "175 1.0748584\n",
      "200 0.9844037\n",
      "225 0.9474324\n",
      "250 0.9647343\n",
      "275 0.9726368\n",
      "300 0.9811408\n",
      "325 0.9790022\n",
      "350 0.9445025\n",
      "375 0.9273362\n",
      "400 0.9272903\n",
      "425 0.927053\n",
      "450 1.0462918\n",
      "475 1.0382823\n",
      "500 1.0591754\n",
      "525 0.91696\n",
      "550 0.9059299\n",
      "575 0.9063452\n",
      "600 0.9071243\n",
      "625 0.90162915\n",
      "650 0.9027205\n",
      "675 0.9875763\n",
      "700 0.90846896\n",
      "725 0.96525365\n",
      "750 0.95074546\n",
      "775 0.9384449\n",
      "800 0.94489145\n",
      "825 0.90697855\n",
      "850 0.90455586\n",
      "875 0.94322515\n",
      "900 0.93506855\n",
      "925 0.8853645\n",
      "950 0.84738857\n",
      "975 0.9397384\n",
      "1000 0.86465555\n",
      "1025 0.85016555\n",
      "1050 0.9170104\n",
      "1075 0.9131109\n",
      "1100 0.8278915\n",
      "1125 0.88499004\n",
      "1150 0.8528265\n",
      "1175 0.8520684\n",
      "1200 0.84699523\n",
      "1225 0.83075655\n",
      "1250 0.79735005\n",
      "1275 0.8154435\n",
      "1300 0.8081497\n",
      "1325 0.79642975\n",
      "1350 0.79191196\n",
      "1375 0.78980064\n",
      "1400 0.76472384\n",
      "1425 0.8166055\n",
      "1450 0.7482425\n",
      "1475 0.77849174\n",
      "1500 0.7381046\n",
      "1525 0.7745316\n",
      "1550 0.7277705\n",
      "1575 0.7082987\n",
      "1600 0.7130283\n",
      "1625 0.7499139\n",
      "1650 0.742618\n",
      "1675 0.7013454\n",
      "1700 0.6978341\n",
      "1725 0.71687704\n",
      "1750 0.69200134\n",
      "1775 0.69031477\n",
      "1800 0.6854121\n",
      "1825 0.6864146\n",
      "1850 0.67438734\n",
      "1875 0.6722048\n",
      "1900 0.666528\n",
      "1925 0.66281235\n",
      "1950 0.65785456\n",
      "1975 0.65548015\n",
      "2000 0.6489248\n",
      "2025 0.6451892\n",
      "2050 0.6394956\n",
      "2075 0.64584273\n",
      "2100 0.6381146\n",
      "2125 0.6306987\n",
      "2150 0.6294192\n",
      "2175 0.62488014\n",
      "2200 0.6348661\n",
      "2225 0.63406676\n",
      "2250 0.6151762\n",
      "2275 0.6281159\n",
      "2300 0.6222322\n",
      "2325 0.61733264\n",
      "2350 0.6143606\n",
      "2375 0.6137604\n",
      "2400 0.60935026\n",
      "2425 0.60987735\n",
      "2450 0.60732913\n",
      "2475 0.6039759\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "sess = tf.InteractiveSession(graph=graph)\n",
    "\n",
    "indim =  X_train.shape[1]\n",
    "outdim = Y_train.shape[1]\n",
    "hiddim = 2\n",
    "layer_dims = [[indim,hiddim],[hiddim,hiddim],[hiddim,outdim]]\n",
    "\n",
    "\n",
    "## setup graph\n",
    "\n",
    "# dataset\n",
    "X_ph = tf.placeholder(tf.float32,shape=[None,indim])\n",
    "Y_ph = tf.placeholder(tf.float32,shape=[None,outdim])\n",
    "batch_size_ph = tf.placeholder(tf.int64)\n",
    "\n",
    "batch_x,batch_y, train_itr_initop,test_itr_initop = setup_tfds(X_ph,Y_ph,batch_size_ph)\n",
    "\n",
    "# inference, loss and minimizer\n",
    "yhat = setup_inference(batch_x,layer_dims)\n",
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=batch_y,logits=yhat)\n",
    "train_op = tf.train.GradientDescentOptimizer(0.005).minimize(loss)\n",
    "\n",
    "\n",
    "## train\n",
    "batch_size = 1\n",
    "feed_dict = {X_ph:X_train, Y_ph:Y_train, batch_size_ph:batch_size}\n",
    "tf.global_variables_initializer().run()\n",
    "sess.run(train_itr_initop,feed_dict)\n",
    "\n",
    "\n",
    "# train loop\n",
    "Lloss = []\n",
    "itr = 2500\n",
    "for i in range(itr):\n",
    "  _,_loss = sess.run([train_op,loss])\n",
    "  Lloss.append(_loss)\n",
    "  if i%int(itr/100) == 0: print(i,_loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.8691669 , 0.03973695, 0.09109618],\n",
       "       [0.3192974 , 0.63251185, 0.0481908 ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.array([[1,0,0],[1,1,1]])\n",
    "\n",
    "## test\n",
    "feed_dict = {X_ph:X_test, Y_ph:X_test, batch_size_ph:X_test.shape[0]}\n",
    "sess.run(test_itr_initop,feed_dict)\n",
    "_yte = sess.run(yhat)\n",
    "_yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_yte.round(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
